{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =================================================================\n",
        "# 1. Data Collection & Loading\n",
        "# =================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# Removed from sklearn.datasets, using uploaded CSV instead\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"1. Libraries Loaded Successfully.\")\n",
        "\n",
        "# --- Load the Dataset from CSV ---\n",
        "DATASET_PATH = 'data (1).csv' # Using the uploaded file name\n",
        "\n",
        "try:\n",
        "    # Load the dataset into a pandas DataFrame\n",
        "    data_frame = pd.read_csv(DATASET_PATH)\n",
        "    print(f\"Data collected and loaded from CSV: {DATASET_PATH}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Dataset not found at {DATASET_PATH}. Please ensure the file is correctly named and located.\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "# =================================================================\n",
        "# 2. Exploratory Data Analysis (EDA)\n",
        "# =================================================================\n",
        "\n",
        "print(\"\\n=================================================================\")\n",
        "print(\"2. Exploratory Data Analysis (EDA)\")\n",
        "print(\"=================================================================\")\n",
        "\n",
        "# Drop unnecessary identifier column and the 'Unnamed: 32' column which contains all NaNs\n",
        "data_frame.drop(columns=['id', 'Unnamed: 32'], axis=1, inplace=True, errors='ignore')\n",
        "print(\"Dropped 'id' and 'Unnamed: 32' columns.\")\n",
        "\n",
        "# Rename the target column for consistency and convert text labels to binary\n",
        "# M (Malignant) -> 0, B (Benign) -> 1\n",
        "data_frame.rename(columns={'diagnosis': 'label'}, inplace=True)\n",
        "data_frame['label'] = data_frame['label'].map({'M': 0, 'B': 1})\n",
        "\n",
        "# Display the first five rows of the dataset\n",
        "print(\"\\n2.1 First five rows of the DataFrame:\")\n",
        "print(data_frame.head())\n",
        "\n",
        "# Display the last five rows of the dataset\n",
        "print(\"\\n2.2 Last five rows of the DataFrame (with 'label'):\")\n",
        "print(data_frame.tail())\n",
        "\n",
        "# Analyze the dataset structure\n",
        "print(\"\\n2.3 Dataset dimensions (.shape):\")\n",
        "print(data_frame.shape)\n",
        "\n",
        "print(\"\\n2.4 Data types and non-null values (.info()):\")\n",
        "data_frame.info()\n",
        "\n",
        "# Check for missing values (Should show all zeros after initial cleaning)\n",
        "print(\"\\n2.5 Missing values check (.isnull().sum()):\")\n",
        "print(data_frame.isnull().sum().loc[lambda x: x > 0]) # Display only columns with NaNs\n",
        "\n",
        "# Display summary statistics\n",
        "print(\"\\n2.6 Summary statistics (.describe()):\")\n",
        "print(data_frame.describe())\n",
        "\n",
        "# Analyze the target variable distribution\n",
        "print(\"\\n2.7 Target variable distribution (.value_counts()):\")\n",
        "# Label 0: Malignant (Cancerous), Label 1: Benign (Non-Cancerous)\n",
        "print(data_frame['label'].value_counts())\n",
        "print(\"\\nInterpretation: The dataset is slightly imbalanced, with more Benign (1) cases than Malignant (0) cases.\")\n",
        "\n",
        "\n",
        "# =================================================================\n",
        "# 3. Data Preprocessing\n",
        "# =================================================================\n",
        "\n",
        "print(\"\\n=================================================================\")\n",
        "print(\"3. Data Preprocessing\")\n",
        "print(\"=================================================================\")\n",
        "\n",
        "# Separate the features (X) and target variable (Y)\n",
        "X = data_frame.drop(columns='label', axis=1)\n",
        "Y = data_frame['label']\n",
        "\n",
        "print(f\"Features (X) shape: {X.shape}\")\n",
        "print(f\"Target (Y) shape: {Y.shape}\")\n",
        "print(\"Features and target separated.\")\n",
        "\n",
        "\n",
        "# =================================================================\n",
        "# 4. Splitting the Dataset\n",
        "# =================================================================\n",
        "\n",
        "print(\"\\n=================================================================\")\n",
        "print(\"4. Splitting the Dataset\")\n",
        "print(\"=================================================================\")\n",
        "\n",
        "# Split the data into training and testing sets (80% training, 20% testing)\n",
        "# stratify=Y ensures equal proportions of the target variable (0 and 1) in both train and test sets.\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X, Y,\n",
        "    test_size=0.2,\n",
        "    random_state=2,\n",
        "    stratify=Y # Crucial for classification problems to maintain class balance\n",
        ")\n",
        "\n",
        "print(f\"Original data size: {X.shape}\")\n",
        "print(f\"Training data size (80%): {X_train.shape}\")\n",
        "print(f\"Testing data size (20%): {X_test.shape}\")\n",
        "\n",
        "\n",
        "# =================================================================\n",
        "# 5. Model Training (Logistic Regression)\n",
        "# =================================================================\n",
        "\n",
        "print(\"\\n=================================================================\")\n",
        "print(\"5. Model Training\")\n",
        "print(\"=================================================================\")\n",
        "\n",
        "# Train a logistic regression model\n",
        "model = LogisticRegression(max_iter=10000) # Increased max_iter for convergence due to unscaled data\n",
        "print(\"Logistic Regression model initialized.\")\n",
        "\n",
        "# Train the model on the training dataset\n",
        "model.fit(X_train, Y_train)\n",
        "print(\"Model training complete.\")\n",
        "\n",
        "\n",
        "# =================================================================\n",
        "# 6. Model Evaluation\n",
        "# =================================================================\n",
        "\n",
        "print(\"\\n=================================================================\")\n",
        "print(\"6. Model Evaluation (Accuracy Score)\")\n",
        "print(\"=================================================================\")\n",
        "#\n",
        "\n",
        "# 6.1 Accuracy on training data:\n",
        "X_train_prediction = model.predict(X_train)\n",
        "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\n",
        "print('Accuracy on training data = ', training_data_accuracy)\n",
        "\n",
        "# 6.2 Accuracy on testing data:\n",
        "X_test_prediction = model.predict(X_test)\n",
        "test_data_accuracy = accuracy_score(Y_test, X_test_prediction)\n",
        "print('Accuracy on test data = ', test_data_accuracy)\n",
        "\n",
        "# Interpretation: High accuracy on both sets indicates the model has learned the patterns well and is not overfitting.\n",
        "\n",
        "\n",
        "# =================================================================\n",
        "# 7. Building a Predictive System\n",
        "# =================================================================\n",
        "\n",
        "print(\"\\n=================================================================\")\n",
        "print(\"7. Building a Predictive System\")\n",
        "print(\"=================================================================\")\n",
        "\n",
        "# Input a sample data point (Malignant case, based on first row of the original dataset)\n",
        "# The uploaded CSV starts with a Malignant case (M -> 0)\n",
        "input_data = (17.99, 10.38, 122.8, 1001, 0.1184, 0.2776, 0.3001, 0.1471, 0.2419, 0.07871, 1.095, 0.9053, 8.589, 153.4, 0.006399, 0.04904, 0.05373, 0.01587, 0.03003, 0.006193, 25.38, 17.33, 184.6, 2019, 0.1622, 0.6656, 0.7119, 0.2654, 0.4601, 0.1189)\n",
        "\n",
        "# Convert the input data into a NumPy array and reshape it\n",
        "input_data_as_numpy_array = np.asarray(input_data)\n",
        "\n",
        "# Reshape the array as we are predicting for only one instance (1 row, 30 columns)\n",
        "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
        "\n",
        "# Predict the output using the trained model\n",
        "prediction = model.predict(input_data_reshaped)\n",
        "print(f\"Prediction result array: {prediction}\")\n",
        "\n",
        "# Output the result\n",
        "if (prediction[0] == 0):\n",
        "    print('The Breast Cancer is Predicted as Malignant (Cancerous)')\n",
        "else:\n",
        "    print('The Breast Cancer is Predicted as Benign (Non-Cancerous)')\n",
        "\n",
        "# Note: This specific input data should ideally predict 0 (Malignant).\n",
        "\n",
        "\n",
        "# =================================================================\n",
        "# Submission Deliverables Summary\n",
        "# =================================================================\n",
        "print(\"\\n=================================================================\")\n",
        "print(\"Submission Deliverables Summary\")\n",
        "print(\"=================================================================\")\n",
        "print(f\"1. .ipynb notebook: Code completed above, using data (1).csv.\")\n",
        "print(f\"2. Training Accuracy: {training_data_accuracy:.4f}\")\n",
        "print(f\"3. Testing Accuracy: {test_data_accuracy:.4f}\")\n",
        "print(\"4. Predictive System Demonstration: Successfully executed in Step 7.\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Libraries Loaded Successfully.\n",
            "Data collected and loaded from CSV: data (1).csv\n",
            "\n",
            "=================================================================\n",
            "2. Exploratory Data Analysis (EDA)\n",
            "=================================================================\n",
            "Dropped 'id' and 'Unnamed: 32' columns.\n",
            "\n",
            "2.1 First five rows of the DataFrame:\n",
            "   label  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
            "0      0        17.99         10.38          122.80     1001.0   \n",
            "1      0        20.57         17.77          132.90     1326.0   \n",
            "2      0        19.69         21.25          130.00     1203.0   \n",
            "3      0        11.42         20.38           77.58      386.1   \n",
            "4      0        20.29         14.34          135.10     1297.0   \n",
            "\n",
            "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
            "0          0.11840           0.27760          0.3001              0.14710   \n",
            "1          0.08474           0.07864          0.0869              0.07017   \n",
            "2          0.10960           0.15990          0.1974              0.12790   \n",
            "3          0.14250           0.28390          0.2414              0.10520   \n",
            "4          0.10030           0.13280          0.1980              0.10430   \n",
            "\n",
            "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
            "0         0.2419  ...         25.38          17.33           184.60   \n",
            "1         0.1812  ...         24.99          23.41           158.80   \n",
            "2         0.2069  ...         23.57          25.53           152.50   \n",
            "3         0.2597  ...         14.91          26.50            98.87   \n",
            "4         0.1809  ...         22.54          16.67           152.20   \n",
            "\n",
            "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
            "0      2019.0            0.1622             0.6656           0.7119   \n",
            "1      1956.0            0.1238             0.1866           0.2416   \n",
            "2      1709.0            0.1444             0.4245           0.4504   \n",
            "3       567.7            0.2098             0.8663           0.6869   \n",
            "4      1575.0            0.1374             0.2050           0.4000   \n",
            "\n",
            "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
            "0                0.2654          0.4601                  0.11890  \n",
            "1                0.1860          0.2750                  0.08902  \n",
            "2                0.2430          0.3613                  0.08758  \n",
            "3                0.2575          0.6638                  0.17300  \n",
            "4                0.1625          0.2364                  0.07678  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "\n",
            "2.2 Last five rows of the DataFrame (with 'label'):\n",
            "     label  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
            "564      0        21.56         22.39          142.00     1479.0   \n",
            "565      0        20.13         28.25          131.20     1261.0   \n",
            "566      0        16.60         28.08          108.30      858.1   \n",
            "567      0        20.60         29.33          140.10     1265.0   \n",
            "568      1         7.76         24.54           47.92      181.0   \n",
            "\n",
            "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
            "564          0.11100           0.11590         0.24390              0.13890   \n",
            "565          0.09780           0.10340         0.14400              0.09791   \n",
            "566          0.08455           0.10230         0.09251              0.05302   \n",
            "567          0.11780           0.27700         0.35140              0.15200   \n",
            "568          0.05263           0.04362         0.00000              0.00000   \n",
            "\n",
            "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
            "564         0.1726  ...        25.450          26.40           166.10   \n",
            "565         0.1752  ...        23.690          38.25           155.00   \n",
            "566         0.1590  ...        18.980          34.12           126.70   \n",
            "567         0.2397  ...        25.740          39.42           184.60   \n",
            "568         0.1587  ...         9.456          30.37            59.16   \n",
            "\n",
            "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
            "564      2027.0           0.14100            0.21130           0.4107   \n",
            "565      1731.0           0.11660            0.19220           0.3215   \n",
            "566      1124.0           0.11390            0.30940           0.3403   \n",
            "567      1821.0           0.16500            0.86810           0.9387   \n",
            "568       268.6           0.08996            0.06444           0.0000   \n",
            "\n",
            "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
            "564                0.2216          0.2060                  0.07115  \n",
            "565                0.1628          0.2572                  0.06637  \n",
            "566                0.1418          0.2218                  0.07820  \n",
            "567                0.2650          0.4087                  0.12400  \n",
            "568                0.0000          0.2871                  0.07039  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "\n",
            "2.3 Dataset dimensions (.shape):\n",
            "(569, 31)\n",
            "\n",
            "2.4 Data types and non-null values (.info()):\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 31 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   label                    569 non-null    int64  \n",
            " 1   radius_mean              569 non-null    float64\n",
            " 2   texture_mean             569 non-null    float64\n",
            " 3   perimeter_mean           569 non-null    float64\n",
            " 4   area_mean                569 non-null    float64\n",
            " 5   smoothness_mean          569 non-null    float64\n",
            " 6   compactness_mean         569 non-null    float64\n",
            " 7   concavity_mean           569 non-null    float64\n",
            " 8   concave points_mean      569 non-null    float64\n",
            " 9   symmetry_mean            569 non-null    float64\n",
            " 10  fractal_dimension_mean   569 non-null    float64\n",
            " 11  radius_se                569 non-null    float64\n",
            " 12  texture_se               569 non-null    float64\n",
            " 13  perimeter_se             569 non-null    float64\n",
            " 14  area_se                  569 non-null    float64\n",
            " 15  smoothness_se            569 non-null    float64\n",
            " 16  compactness_se           569 non-null    float64\n",
            " 17  concavity_se             569 non-null    float64\n",
            " 18  concave points_se        569 non-null    float64\n",
            " 19  symmetry_se              569 non-null    float64\n",
            " 20  fractal_dimension_se     569 non-null    float64\n",
            " 21  radius_worst             569 non-null    float64\n",
            " 22  texture_worst            569 non-null    float64\n",
            " 23  perimeter_worst          569 non-null    float64\n",
            " 24  area_worst               569 non-null    float64\n",
            " 25  smoothness_worst         569 non-null    float64\n",
            " 26  compactness_worst        569 non-null    float64\n",
            " 27  concavity_worst          569 non-null    float64\n",
            " 28  concave points_worst     569 non-null    float64\n",
            " 29  symmetry_worst           569 non-null    float64\n",
            " 30  fractal_dimension_worst  569 non-null    float64\n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 137.9 KB\n",
            "\n",
            "2.5 Missing values check (.isnull().sum()):\n",
            "Series([], dtype: int64)\n",
            "\n",
            "2.6 Summary statistics (.describe()):\n",
            "            label  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
            "count  569.000000   569.000000    569.000000      569.000000   569.000000   \n",
            "mean     0.627417    14.127292     19.289649       91.969033   654.889104   \n",
            "std      0.483918     3.524049      4.301036       24.298981   351.914129   \n",
            "min      0.000000     6.981000      9.710000       43.790000   143.500000   \n",
            "25%      0.000000    11.700000     16.170000       75.170000   420.300000   \n",
            "50%      1.000000    13.370000     18.840000       86.240000   551.100000   \n",
            "75%      1.000000    15.780000     21.800000      104.100000   782.700000   \n",
            "max      1.000000    28.110000     39.280000      188.500000  2501.000000   \n",
            "\n",
            "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
            "count       569.000000        569.000000      569.000000           569.000000   \n",
            "mean          0.096360          0.104341        0.088799             0.048919   \n",
            "std           0.014064          0.052813        0.079720             0.038803   \n",
            "min           0.052630          0.019380        0.000000             0.000000   \n",
            "25%           0.086370          0.064920        0.029560             0.020310   \n",
            "50%           0.095870          0.092630        0.061540             0.033500   \n",
            "75%           0.105300          0.130400        0.130700             0.074000   \n",
            "max           0.163400          0.345400        0.426800             0.201200   \n",
            "\n",
            "       symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
            "count     569.000000  ...    569.000000     569.000000       569.000000   \n",
            "mean        0.181162  ...     16.269190      25.677223       107.261213   \n",
            "std         0.027414  ...      4.833242       6.146258        33.602542   \n",
            "min         0.106000  ...      7.930000      12.020000        50.410000   \n",
            "25%         0.161900  ...     13.010000      21.080000        84.110000   \n",
            "50%         0.179200  ...     14.970000      25.410000        97.660000   \n",
            "75%         0.195700  ...     18.790000      29.720000       125.400000   \n",
            "max         0.304000  ...     36.040000      49.540000       251.200000   \n",
            "\n",
            "        area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
            "count   569.000000        569.000000         569.000000       569.000000   \n",
            "mean    880.583128          0.132369           0.254265         0.272188   \n",
            "std     569.356993          0.022832           0.157336         0.208624   \n",
            "min     185.200000          0.071170           0.027290         0.000000   \n",
            "25%     515.300000          0.116600           0.147200         0.114500   \n",
            "50%     686.500000          0.131300           0.211900         0.226700   \n",
            "75%    1084.000000          0.146000           0.339100         0.382900   \n",
            "max    4254.000000          0.222600           1.058000         1.252000   \n",
            "\n",
            "       concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
            "count            569.000000      569.000000               569.000000  \n",
            "mean               0.114606        0.290076                 0.083946  \n",
            "std                0.065732        0.061867                 0.018061  \n",
            "min                0.000000        0.156500                 0.055040  \n",
            "25%                0.064930        0.250400                 0.071460  \n",
            "50%                0.099930        0.282200                 0.080040  \n",
            "75%                0.161400        0.317900                 0.092080  \n",
            "max                0.291000        0.663800                 0.207500  \n",
            "\n",
            "[8 rows x 31 columns]\n",
            "\n",
            "2.7 Target variable distribution (.value_counts()):\n",
            "label\n",
            "1    357\n",
            "0    212\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Interpretation: The dataset is slightly imbalanced, with more Benign (1) cases than Malignant (0) cases.\n",
            "\n",
            "=================================================================\n",
            "3. Data Preprocessing\n",
            "=================================================================\n",
            "Features (X) shape: (569, 30)\n",
            "Target (Y) shape: (569,)\n",
            "Features and target separated.\n",
            "\n",
            "=================================================================\n",
            "4. Splitting the Dataset\n",
            "=================================================================\n",
            "Original data size: (569, 30)\n",
            "Training data size (80%): (455, 30)\n",
            "Testing data size (20%): (114, 30)\n",
            "\n",
            "=================================================================\n",
            "5. Model Training\n",
            "=================================================================\n",
            "Logistic Regression model initialized.\n",
            "Model training complete.\n",
            "\n",
            "=================================================================\n",
            "6. Model Evaluation (Accuracy Score)\n",
            "=================================================================\n",
            "Accuracy on training data =  0.9582417582417583\n",
            "Accuracy on test data =  0.9649122807017544\n",
            "\n",
            "=================================================================\n",
            "7. Building a Predictive System\n",
            "=================================================================\n",
            "Prediction result array: [0]\n",
            "The Breast Cancer is Predicted as Malignant (Cancerous)\n",
            "\n",
            "=================================================================\n",
            "Submission Deliverables Summary\n",
            "=================================================================\n",
            "1. .ipynb notebook: Code completed above, using data (1).csv.\n",
            "2. Training Accuracy: 0.9582\n",
            "3. Testing Accuracy: 0.9649\n",
            "4. Predictive System Demonstration: Successfully executed in Step 7.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJmu9ftcbhgK",
        "outputId": "a880acbd-9fbb-4723-cd3a-b0e9c866c9d3"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}